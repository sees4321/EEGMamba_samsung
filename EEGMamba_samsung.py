import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Function


# ---------------- GRL (Gradient Reversal Layer) ---------------- #
class GradientReversalFn(Function):
    @staticmethod
    def forward(ctx, x, lambda_):
        ctx.lambda_ = lambda_
        # forward ì—ì„œëŠ” ì•„ë¬´ ê²ƒë„ ì•ˆ í•˜ê³  ê·¸ëŒ€ë¡œ ì „ë‹¬
        return x.view_as(x)

    @staticmethod
    def backward(ctx, grad_output):
        # ì—­ì „íŒŒì—ì„œ ê¸°ìš¸ê¸°ë¥¼ -lambda ë°°ë¡œ ë’¤ì§‘ì–´ì¤Œ
        return -ctx.lambda_ * grad_output, None


def grad_reverse(x, lambda_):
    """
    x : (B, D)
    lambda_ : float ìŠ¤ì¹¼ë¼
    """
    return GradientReversalFn.apply(x, lambda_)
# --------------------------------------------------------------- #





# ---------------- Tokenize ---------------- #
class Tokenize1D(nn.Module):
    def __init__(self, in_ch, dim, patch_kernel=13, patch_stride=1,
                 pool_kernel=3, dropout_p=0.5):
        super().__init__()

        # 1. temporal Conv: (B, in_ch, L) -> (B, dim, L')
        self.conv = nn.Conv1d(
            in_channels=in_ch,
            out_channels=dim,
            kernel_size=patch_kernel,
            stride=patch_stride,
            padding=patch_kernel // 2,
        )

        self.act = nn.GELU()

        # 2. optional pooling

        self.pool = nn.MaxPool1d(kernel_size=pool_kernel, stride=pool_kernel)

        # 3. optional dropout
        self.dropout = nn.Dropout(dropout_p) if dropout_p > 0 else nn.Identity()

        self.cls_token = nn.Parameter(torch.zeros(1, 1, dim))
        self.norm = nn.LayerNorm(dim)
        nn.init.trunc_normal_(self.cls_token, std=0.02)

    def forward(self, x):  # x: (B, C, L)
        h = self.conv(x)          # (B, D, L')
        h = self.act(h)           # ë¹„ì„ í˜•
        h = self.pool(h)          # (B, D, L''), í•„ìš” ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ
        h = self.dropout(h)

        h = h.transpose(1, 2)     # (B, N, D)
        B, N, D = h.shape

        cls = self.cls_token.expand(B, 1, D)   # (B,1,D)
        h = torch.cat([cls, h], dim=1)         # (B, N+1, D)
        h = self.norm(h)
        return h

class Tokenize2D(nn.Module):

    def __init__(self, in_ch, dim,
                 patch_kernel=(5,5), patch_stride=(2,2),
                 dropout_p=0.5):
        super().__init__()

        self.conv = nn.Conv2d(
            in_channels=in_ch,
            out_channels=dim,
            kernel_size=patch_kernel,
            stride=patch_stride,
            padding=(patch_kernel[0]//2, patch_kernel[1]//2)
        )
        self.act = nn.GELU()
        self.dropout = nn.Dropout(dropout_p) if dropout_p > 0 else nn.Identity()

        self.cls_token = nn.Parameter(torch.zeros(1,1,dim))
        self.norm = nn.LayerNorm(dim)
        nn.init.trunc_normal_(self.cls_token, std=0.02)

    def forward(self, x):  # x: (B, C, F, T)
        h = self.conv(x)         # (B, D, F', T')
        h = self.act(h)
        h = self.dropout(h)

        B, D, Fp, Tp = h.shape
        h = h.view(B, D, Fp*Tp)  # (B, D, N)
        h = h.transpose(1, 2)    # (B, N, D)

        cls = self.cls_token.expand(B, 1, D)
        h = torch.cat([cls, h], dim=1)  # (B, N+1, D)
        h = self.norm(h)
        return h

# --------------------------------------------------------------- #





# ---------------- DSConvBlock (1D ìš© feature extractor) ---------------- #

# class DSConvBlock(nn.Module):
#     def __init__(self, dim, dim_2, kernel_size=13):
#         super().__init__()
#         padding = kernel_size // 2
#         self.dw = nn.Conv1d(dim, dim, kernel_size, padding=padding)
#         self.act = nn.GELU()
#
#     def forward(self, x):   # (B,N,D)
#
#         residual = x
#         h = x.transpose(1, 2)       # (B,D,N)
#         h = self.dw(h)
#         h = h.transpose(1, 2)       # (B,N,D)
#         h = self.act(h)
#
#         return residual + h

# ---------------- DSConvBlock (2D ìš© feature extractor) ---------------- #

class DSConvBlock(nn.Module):
    def __init__(self, dim, dim_2, kernel_size=13):
        super().__init__()
        padding = kernel_size // 2

        # (B, 1, dim, L+1) â†’ (B, dim_2, dim, L+1)
        self.conv2d = nn.Conv2d(
            in_channels=1,
            out_channels=dim_2,
            kernel_size=(1, kernel_size),
            padding=(0, padding)
        )

        # dim ì¶• ì••ì¶• Conv2d: (B, dim_2, dim, L+1) â†’ (B, dim_2, 1, L+1)
        self.compress = nn.Conv2d(
            in_channels=dim_2,
            out_channels=dim_2,
            kernel_size=(dim, 1),
            stride=(1, 1)
        )

        self.norm = nn.LayerNorm(dim_2)  # (B, N, dim_2) ì— ì‚¬ìš©í•  ì˜ˆì •
        self.act = nn.GELU()

    def forward(self, x):  # x: (B, N, dim)

        # conv path
        h = x.transpose(1, 2)   # (B, dim, N)
        h = h.unsqueeze(1)      # (B, 1, dim, N)
        h = self.conv2d(h)      # (B, dim_2, dim, N)

        h = self.compress(h)    # (B, dim_2, 1, N)
        h = h.squeeze(2)        # (B, dim_2, N)

        h = h.transpose(1, 2)   # (B, N, dim_2)

        # ì—¬ê¸°ì„œë§Œ LayerNorm + GELU
        h = self.norm(h)        # (B, N, dim_2)
        h = self.act(h)

        return h                # (B, N, dim_2)

# --------------------------------------------------------------- #






# ---------------- Task-Aware MoE ---------------- #

class ExpertMLP(nn.Module):
    def __init__(self, dim, drop=0.5):
        super().__init__()
        self.ff = nn.Sequential(
            nn.Linear(dim, dim),
            nn.GELU(),
            nn.Dropout(drop),
        )

    def forward(self, x):
        return self.ff(x)

class TaskAwareMoE(nn.Module):
    def __init__(self,
                 dim,
                 num_experts,        # task experts ê°œìˆ˜ N_e
                 num_tasks,
                 k_top=2,            # Top-k ì—ì„œ k
                 drop=0.5,
                 noisy=True,
                 expert_class=ExpertMLP,

                 ):
        super().__init__()
        self.noisy = noisy
        self.num_experts = num_experts
        self.k_top = k_top

        self.num_tasks = num_tasks

        # task embedding
        self.task_embed = nn.Embedding(num_tasks, dim)

        # task experts (ê³µìš©)
        self.experts = nn.ModuleList([expert_class(dim, drop=drop) for _ in range(num_experts)])

        # universal expert 1ê°œ
        self.universal_expert = expert_class(dim, drop=drop)

        # gate / noise : T_cat (2D) -> N_e
        self.gate  = nn.Linear(dim * 2, num_experts)
        self.noise = nn.Linear(dim * 2, num_experts)

        # í†µê³„ìš© ë²„í¼
        self.track_stats = False
        self.register_buffer(
            "expert_hist", torch.zeros(num_tasks, num_experts)
        )  # [task, expert] ì„ íƒ íšŸìˆ˜
        self.register_buffer(
            "token_hist", torch.zeros(num_tasks)
        )  # taskë³„, í† í°*topk ê°œìˆ˜(ë˜ëŠ” í† í° ê°œìˆ˜)

    def reset_stats(self):
        if hasattr(self, "expert_hist"):
            self.expert_hist.zero_()
        if hasattr(self, "token_hist"):
            self.token_hist.zero_()


    def forward(self, tokens, task_ids):

        B, N, D = tokens.shape

        # ---- 1) task-aware ì…ë ¥ ë§Œë“¤ê¸° (ì‹ 9) ----
        t_vec = self.task_embed(task_ids)                    # (B,D)

        t_broadcast = t_vec.unsqueeze(1).expand(B, N, D)  # (B,N,D)

        T_cat = torch.cat([tokens, t_broadcast], dim=-1)     # (B,N,2D)

        # ---- 2) gate logits + noise  ----

        logits = self.gate(T_cat)  # (B,N,E)

        if self.training and self.noisy:

            noise_std = F.softplus(self.noise(T_cat))  # (B,N,E)
            eps = torch.randn_like(logits)                   # í‘œì¤€ ê°€ìš°ì‹œì•ˆ
            logits = logits + eps * noise_std

        # ---- 3) Top-k sparse gating (ì‹ 8 ì˜ Top_k) ----
        # logits: (B,N,E)
        k = min(self.k_top, self.num_experts)
        topk_vals, topk_idx = torch.topk(logits, k=k, dim=-1)    # (B,N,k)

        # ë‚˜ë¨¸ì§€ expertëŠ” -inf ë¡œ ë§ˆìŠ¤í‚¹ â†’ softmax í›„ 0ì´ ë¨
        mask = torch.full_like(logits, float('-inf'))            # (B,N,E)
        mask.scatter_(-1, topk_idx, topk_vals)                   # ìƒìœ„ k ìœ„ì¹˜ë§Œ ê°’ ìœ ì§€
        gates = F.softmax(mask, dim=-1)                          # (B,N,E)

        # ================= í†µê³„ ê¸°ë¡ (top-k ê¸°ì¤€) =================
        if self.track_stats:
            with torch.no_grad():
                # gates>0 ì¸ expert ëŠ” top-k ì— í¬í•¨ëœ ê²ƒ
                # ë§ˆìŠ¤í‚¹ ë•Œë¬¸ì— ë‚˜ë¨¸ì§€ëŠ” ê±°ì˜ ì •í™•íˆ 0
                selected = (gates > 0)  # (B,N,E) bool

                for b in range(B):
                    t_id = int(task_ids[b].item())

                    # í† í° * k ê°œìˆ˜ë§Œí¼ ì¹´ìš´íŠ¸í•˜ê³  ì‹¶ë‹¤ë©´:
                    self.token_hist[t_id] += selected[b].sum().item()
                    # expertë³„ top-k í¬í•¨ íšŸìˆ˜ ëˆ„ì 
                    self.expert_hist[t_id] += selected[b].sum(dim=0).float()
        # =========================================================

        # ---- 4) task experts ì¶œë ¥ (E_i(T)) ----
        expert_outs = torch.stack([e(tokens) for e in self.experts],dim=-2)

        T_task = torch.sum(gates.unsqueeze(-1) * expert_outs, dim=-2)  # (B,N,D)

        # ---- 5) universal expert + weight Ï‰ (ì‹ 10) ----
        T_univ = self.universal_expert(tokens)           # (B,N,D)

        # Max(e(T)) : ê²Œì´íŠ¸ í™•ë¥ ì—ì„œ ìµœëŒ€ê°’
        max_e, _ = gates.max(dim=-1, keepdim=True)       # (B,N,1)
        omega = 1.0 - max_e                              # (B,N,1)

        T_out = T_task + omega * T_univ                  # (B,N,D)

        return T_out

# --------------------------------------------------------------- #






# ---------------- StreamBranch ---------------- #

class FeatureExtractor(nn.Module):
    def __init__(self, dim, dim_2, depth):
        super().__init__()
        self.blocks = nn.ModuleList([DSConvBlock(dim, dim_2, kernel_size=13) for _ in range(depth)])

    def forward(self, x):  # (B,N,D)
        for blk in self.blocks:
            x = blk(x)
        return x

class StreamBranch1D(nn.Module):
    def __init__(self, in_ch, dim, dim_2,
                 patch_kernel=13, patch_stride=2,
                 feat_depth=1, moe_experts=4, num_tasks=2):
        super().__init__()
        self.tokenizer = Tokenize1D(
            in_ch=in_ch, dim=dim,
            patch_kernel=patch_kernel,
            patch_stride=patch_stride
        )
        self.Deep4block = FeatureExtractor(dim=dim, dim_2 = dim_2, depth=feat_depth)

        expert_class = ExpertMLP

        self.moe = TaskAwareMoE(dim=dim_2, num_experts=moe_experts, num_tasks=num_tasks, drop=0.5, expert_class=expert_class)
        self.norm = nn.LayerNorm(dim_2)

    def forward(self, x_stream, task_ids):  # x_stream: (B, C, L)
        h = self.tokenizer(x_stream)        # (B, N+1, D)
        h = self.Deep4block(h)
        h = self.moe(h, task_ids)
        h = self.norm(h)
        cls = h[:, 0, :]
        return cls


class StreamBranch2D(nn.Module):
    def __init__(self, in_ch, dim, dim_2,
                 patch_kernel=(5,5), patch_stride=(2,2),
                 feat_depth=1, moe_experts=4, num_tasks=2):
        super().__init__()
        self.tokenizer = Tokenize2D(
            in_ch=in_ch, dim=dim,
            patch_kernel=patch_kernel,
            patch_stride=patch_stride
        )
        self.Deep4block = FeatureExtractor(dim=dim, dim_2 = dim_2, depth=feat_depth)

        # â˜… Expert ì„ íƒ
        expert_class = ExpertMLP

        self.moe = TaskAwareMoE(dim=dim_2, num_experts=moe_experts, num_tasks=num_tasks, drop=0.5, expert_class=expert_class)
        self.norm = nn.LayerNorm(dim_2)

    def forward(self, x_stream, task_ids):  # x_stream: (B, C, F, T)
        h = self.tokenizer(x_stream)        # (B, N+1, D)
        h = self.Deep4block(h)
        h = self.moe(h, task_ids)
        h = self.norm(h)
        cls = h[:, 0, :]
        return cls

# --------------------------------------------------------------- #







# ---------------- 8ìŠ¤íŠ¸ë¦¼ ìœµí•© + ìµœì¢… ë¶„ë¥˜ ---------------- #

class MultiStreamModel(nn.Module):
    def __init__(
        self,
        in_ch,
        dim=2,
        dim_2 = 32,
        num_tasks=5,
        patch_kernel=13,
        patch_stride=2,
        feat_depth=1,
        moe_experts=4,
        selected_streams=None,
        all_stream_names=None,
        raw_kernel_sizes=None,

        use_dann=False,
        num_domains=49,
    ):
        super().__init__()

        self.use_dann = use_dann
        self.num_tasks = num_tasks

        # ì›ë˜ stream ì´ë¦„ë“¤ (configì—ì„œ ë„˜ì–´ì˜¨ ê²ƒ)
        self.all_stream_names = list(all_stream_names)
        self.base_stream_names = list(selected_streams)

        # raw ì „ìš© kernel size ë¦¬ìŠ¤íŠ¸ (ì—†ìœ¼ë©´ None)
        self.raw_kernel_sizes = raw_kernel_sizes

        # ì–´ë–¤ ìŠ¤íŠ¸ë¦¼ì„ 2Dë¡œ ì²˜ë¦¬í• ì§€ (ì§€ê¸ˆì€ fftë§Œ)
        self.stream_2d = {"fft"}

        # ì‹¤ì œ ë¸Œëœì¹˜ ëª¨ë“ˆë“¤ì´ ë“¤ì–´ê°ˆ dict
        branches = {}

        # â˜… ì‹¤ì œ gatingì— ë“¤ì–´ê°ˆ ìŠ¤íŠ¸ë¦¼ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        #   ì˜ˆ: ["fft", "raw_k13", "raw_k25", "hilb"]
        self.stream_names = []

        # â˜… ê° ë¸Œëœì¹˜ê°€ x_dictì˜ ì–´ë–¤ keyë¥¼ ì°¸ì¡°í•˜ëŠ”ì§€ ë§¤í•‘
        #   ì˜ˆ: {"raw_k13": "raw", "raw_k25": "raw", "fft": "fft"}
        self.base_for_branch = {}

        for base_name in self.base_stream_names:
            # ----- raw ìŠ¤íŠ¸ë¦¼: ì—¬ëŸ¬ kernel ì‚¬ì´ì¦ˆë¡œ í™•ì¥ -----
            if base_name == "raw" and self.raw_kernel_sizes is not None and len(self.raw_kernel_sizes) > 0:
                for k in self.raw_kernel_sizes:
                    branch_key = f"raw_k{k}"  # ì˜ˆ: "raw_k13"
                    self.stream_names.append(branch_key)
                    self.base_for_branch[branch_key] = "raw"

                    # rawëŠ” 1D ìŠ¤íŠ¸ë¦¼ì´ë¯€ë¡œ StreamBranch1D ì‚¬ìš©
                    branches[branch_key] = StreamBranch1D(
                        in_ch=in_ch,
                        dim=dim,
                        dim_2=dim_2,
                        patch_kernel=k,  # â˜… ì—¬ê¸°ì„œ kernel_size ë‹¤ë¥´ê²Œ
                        patch_stride=patch_stride,
                        feat_depth=feat_depth,
                        moe_experts=moe_experts,
                        num_tasks=num_tasks,
                    )

            # ----- ê·¸ ì™¸ ìŠ¤íŠ¸ë¦¼ (fft, hilb, delta, ... ) -----
            else:
                branch_key = base_name
                self.stream_names.append(branch_key)
                self.base_for_branch[branch_key] = base_name

                if base_name in self.stream_2d:
                    branches[branch_key] = StreamBranch2D(
                        in_ch=in_ch,
                        dim=dim,
                        dim_2=dim_2,
                        patch_kernel=(5, 5),
                        patch_stride=(2, 2),
                        feat_depth=feat_depth,
                        moe_experts=moe_experts,
                        num_tasks=num_tasks,
                    )
                else:
                    branches[branch_key] = StreamBranch1D(
                        in_ch=in_ch,
                        dim=dim,
                        dim_2=dim_2,
                        patch_kernel=patch_kernel,  # ê¸°ë³¸ 1D kernel
                        patch_stride=patch_stride,
                        feat_depth=feat_depth,
                        moe_experts=moe_experts,
                        num_tasks=num_tasks,
                    )

        self.branches = nn.ModuleDict(branches)

        # Linear ê²Œì´íŠ¸
        self.stream_gate_linear = nn.Linear(dim_2, 1)
        self.final_norm = nn.LayerNorm(dim_2)

        # ğŸ”¥ Taskë³„ classifier head: ê° taskë§ˆë‹¤ Linear í•˜ë‚˜ì”©
        # ì—¬ê¸°ì„œëŠ” ëª¨ë“  taskê°€ binary ë¼ê³  ê°€ì •í•´ì„œ out_features=2ë¡œ í†µì¼
        self.task_heads = nn.ModuleDict({
            str(t): nn.Linear(dim_2, 2) for t in range(num_tasks)
        })

        # ====== DANN domain classifier ======
        if self.use_dann:
            self.domain_classifier = nn.Sequential(
                nn.Linear(dim_2, dim_2 // 2),
                nn.ReLU(),
                nn.Linear(dim_2 // 2, num_domains),
            )
        else:
            self.domain_classifier = None
        # ====================================

    def forward(self, x_dict, task_ids, grl_lambda=1.0):

        stream_feats = []
        for key in self.stream_names: # ê° stream ë³„ë¡œ ê²°ê³¼ ë„ì¶œ
            base_name = self.base_for_branch[key]
            x_stream = x_dict[base_name]

            cls_s = self.branches[key](x_stream, task_ids)
            stream_feats.append(cls_s)

        # (B, num_streams, dim_2)
        H = torch.stack(stream_feats, dim=1) # ê° streamì— ëŒ€í•œ ê²°ê³¼ í•©ì¹˜ê¸°

        scores = self.stream_gate_linear(H)   # (B, num_streams, 1)
        alpha = F.softmax(scores, dim=1)
        fused = (alpha * H).sum(dim=1)        # (B, dim_2)

        fused = self.final_norm(fused)        # shared backbone output

        # ğŸ”¥ taskë³„ head ì ìš©
        B = fused.size(0)
        task_logits = fused.new_zeros(B, 2)   # binary í´ë˜ìŠ¤ë¼ê³  ê°€ì •

        for t in range(self.num_tasks):
            mask = (task_ids == t)            # (B,)
            if not mask.any():
                continue
            head = self.task_heads[str(t)]
            fused_t = fused[mask]             # (B_t, dim_2)
            task_logits[mask] = head(fused_t) # (B_t, 2)

        if self.use_dann:
            feat_rev = grad_reverse(fused, grl_lambda)
            domain_logits = self.domain_classifier(feat_rev)
            return task_logits, domain_logits

        return task_logits